---
layout: project
title: GENEA Challenge 2020
permalink: /GENEAchallenge2020/
---


<p align="center">
  <b style="font-size: 45px;"> A large, crowdsourced evaluation of gesture generation systems on common data: <br/> The GENEA Challenge 2020 </b>
  <p style="font-size: 32px;"> <a href="https://svito-zar.github.io/">Taras Kucherenko</a>, <a href="http://www.patrikjonell.se">Patrik Jonell</a>,  <a href="https://sites.google.com/view/youngwoo-yoon/">Youngwoo Yoon</a>, <a href="https://www.pieterwolfert.com/"> Pieter Wolfert</a>,  <a href="https://people.kth.se/~ghe/"> Gustav Eje Henter</a> </p>
</p>

<p align="center">
 <a href="https://zenodo.org/record/4094697#.YP69xTqxU5k" style="font-size: 28px; text-decoration: none">[first workshop paper]  </a>  
 <a style="font-size: 35px; text-decoration: none"> |   </a> 
 <a href="https://doi.org/10.1145/3397481.3450692" style="font-size: 28px; text-decoration: none">[conference paper (IUI 2021)]   </a>   
</p>

<div style="text-align:center"><img src="../assets/2021_GENEA.jpg" alt="GENEA figure" align="middle"></div>

&nbsp;

### SUMMARY

<p>Hand and body gestures play an important role in human communication, and automatically generating such gestures is therefore an important research area for conversational agents such as virtual avatars and social robots. To help the field of automated gesture generation move forward, we ran the first gesture-generation challenge &ndash; the GENEA Challenge 2020 &ndash; comparing many different gesture-generation methods on the same data in a large, crowdsourced evaluation. The intent is to help the community figure out what is important for good automatic gesture generation.</p>
<p>This page collects papers, videos, and other resources from our challenge. For more information about the design and results of the challenge, and what we learned from it, please see <a href="https://doi.org/10.1145/3397481.3450692">our main paper on the challenge, published at IUI 2021</a>.</p>


&nbsp;

***
&nbsp;

### Main video explaining the paper:

<iframe width="660" height="415" src="https://www.youtube.com/embed/QmaoKRzoVwM" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

&nbsp;

***
&nbsp;

### Open-source materials:

<div style="text-align:left">
<img style="float: left; border: 6px solid white;" src="../assets/Avatar.jpg" >
<br>
<p style="font-size: 18px;"> User-study video stimuli  <a href="https://zenodo.org/record/4080919"> DOI: 10.5281/zenodo.4080919 </a> </p> 
<p style="font-size: 18px;"> 3D coordinates of submitted motion <a href="https://zenodo.org/record/4088319"> DOI: 10.5281/zenodo.4088319 </a> </p> 
<p style="font-size: 18px;"> Submitted BVH files <a href="https://zenodo.org/record/4785119"> DOI: 10.5281/zenodo.4785119 </a> </p> 
<br>
<br>
</div>

<div style="text-align:left">
<img style="float: left; border: 6px solid white;" src="../assets/GitHub_logo.png" >
<br>
<p style="font-size: 18px;"> Code for visualising gesture motion  <a href="https://github.com/jonepatr/genea_visualizer"> GENEA visualizer </a> </p> 
<p style="font-size: 18px;"> Code for computing the numerical evaluation metrics <a href="https://github.com/genea-workshop/genea_numerical_evaluations"> GENEA numerical evaluations  </a> </p> 
<br>
<br>
<br>
</div>

<div style="text-align:left">
<img style="float: left; border: 6px solid white;" src="../assets/table.jpg" >
<br>
<p style="font-size: 18px;"> User-study subjective results and scripts to analyze them <a href="https://zenodo.org/record/4088250"> DOI: 10.5281/zenodo.4088250 </a> </p> 
<br>
<br>
<br>
<br>
<br>
</div>

<div style="text-align:left">
<img style="float: left; border: 3px solid white;" src="../assets/paper_icon.png" >
<p style="font-size: 18px;"> <a href="https://zenodo.org/record/4088600"> The StyleGestures entry to the GENEA Challenge 2020   </a> </p> 
<p style="font-size: 18px;"> <a href="https://zenodo.org/record/4088609"> The FineMotion entry to the GENEA Challenge 2020  </a> </p> 
<p style="font-size: 18px;"> <a href="https://ieeexplore.ieee.org/abstract/document/9414660"> Double-DCCCAE: Estimation of Body Gestures From Speech Waveform  </a> </p> 
<p style="font-size: 18px;"> <a href="https://zenodo.org/record/4090879"> CGVU: Semantics-guided 3D Body Gesture Synthesis </a> </p> 
<p style="font-size: 18px;"> <a href="https://ieeexplore.ieee.org/abstract/document/9454931"> Speech Gesture Generation from Acoustic and Textual Information using LSTMs  </a> </p> 
</div>

&nbsp;

***
&nbsp;

### Citation format:
```
@inproceedings{kucherenko2021large,
author = {Kucherenko, Taras and Jonell, Patrik and Yoon, Youngwoo and Wolfert, Pieter and Henter, Gustav Eje},
title = {A Large, Crowdsourced Evaluation of Gesture Generation Systems on Common Data: The {GENEA} {C}hallenge 2020},
year = {2021},
isbn = {9781450380171},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3397481.3450692},
doi = {10.1145/3397481.3450692},
booktitle = {26th International Conference on Intelligent User Interfaces},
pages = {11--21},
numpages = {11},
keywords = {evaluation paradigms, conversational agents, gesture generation},
location = {College Station, TX, USA},
series = {IUI '21}
}
```


