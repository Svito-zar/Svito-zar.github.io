---
layout: page
title: Publications
permalink: /publications/
---

## Selected Publications

The complete publication list can be found on \[[Google Scholar\]](https://scholar.google.com/citations?user=aI_16pYAAAAJ&hl=en), \[[DBLP\]](https://dblp.uni-trier.de/pers/hd/k/Kucherenko:Taras), and \[[ResearchGate\]](https://www.researchgate.net/profile/Taras_Kucherenko).

### 2023

* Simba Nyatsanga, **Taras Kucherenko**, Chaitanya  Ahuja, Gustav Eje Henter, and Michael Neff. (2023). *A Comprehensive Review of Data-Driven Co-Speech Gesture Generation*. In Computer Graphics Forum (EuroGraphics 2023). \[[Paper\]](https://arxiv.org/abs/2301.05339)

### 2022

* Youngwoo Yoon\*, Pieter Wolfert\*, **Taras Kucherenko**\*, Carla Viegas, Teodor Nikolov, Mihail Tsakov, and Gustav Eje Henter. 2022. *The GENEA Challenge 2022: A large evaluation of data-driven co-speech gesture generation*. In Proceedings of the ACM International Conference on Multimodal Interaction (ICMI ’22). ACM. \[[Paper\]](https://dl.acm.org/doi/10.1145/3536221.3558058) \[[Project Page\]](https://youngwoo-yoon.github.io/GENEAchallenge2022/) \[[Video\]](https://www.youtube.com/watch?v=4n02wXGGnd0)

* Yuan He, André Pereira, and **Taras Kucherenko**. *Evaluating Data-Driven Co-Speech Gestures of Embodied Conversational Agents through Real-Time Interaction.* International Conference on Intelligent Virtual Agents (IVA’22). 2022 \[[Paper\]](https://dl.acm.org/doi/10.1145/3514197.3549697?cid=99659309831) \[[Project Page\]](https://www.yaeh.io/research/hci/presentingbot)

* **Taras Kucherenko**, Rajmund Nagy, Michael Neff, Hedvig Kjellström, and Gustav Eje Henter. *Multimodal analysis of the predictability of hand-gesture properties*. 21st International Conference on Autonomous Agents and Multiagent Systems (AAMAS). 2022 \[[Paper\]](https://ifaamas.org/Proceedings/aamas2022/pdfs/p770.pdf) \[[Project Page\]](../_posts/2021-07-30-Speech2Gest2Prop.md) \[[Video\]](https://www.youtube.com/watch?v=uK7R3YYxC9Q)

### 2021


* **Taras Kucherenko**, Rajmund Nagy, Patrik Jonell, Michael Neff, Hedvig Kjellström, and Gustav Eje Henter. *Speech2Properties2Gestures: Gesture-Property Prediction as a Tool for Generating Representational Gestures from Speech.* International Conference on Intelligent Virtual Agents (IVA’21). 2021 \[[Paper\]](https://dl.acm.org/doi/10.1145/3472306.3478333?cid=99659309831) \[[Project Page\]](../_posts/2021-07-30-Speech2Gest2Prop.md) <span style="font-size: 11px;" class="badge badge-info mb-2"> Honorable Mention Award<i class="fas fa-award"></i></span>


* Rajmund Nagy\*, **Taras Kucherenko**\*, Birger Moell, André Pereira, Hedvig Kjellström, and Ulysses Bernardet. *A Framework for Integrating Gesture Generation Models into Interactive Conversational Agents*. 20th International Conference on Autonomous Agents and Multiagent Systems (AAMAS). \[[Paper\]](http://www.ifaamas.org/Proceedings/aamas2021/pdfs/p1779.pdf) \[[Code\]](https://github.com/nagyrajmund/gesticulating_agent_unity) \[[Video\]](https://www.youtube.com/watch?v=jhgUBS0125A) \[[Project Page\]](https://nagyrajmund.github.io/project/gesturebot/)

* **Taras  Kucherenko**,  Dai  Hasegawa, Naoshi Kaneko, Gustav  Eje  Henter, and Hedvig Kjellström.
*Moving fast and slow: Analysis of representations and post-processing in speech-driven automatic gesture generation.* International Journal of Human-Computer Interaction. 2021
\[[Paper\]](https://www.tandfonline.com/doi/full/10.1080/10447318.2021.1883883) \[[Code\]](https://github.com/GestureGeneration/Speech_driven_gesture_generation_with_autoencoder) \[[Project Page\]](../_posts/2020-01-14-Audio2Gestures.md)

* **Taras Kucherenko**\*, Patrik Jonell\*, Youngwoo Yoon\*, Pieter Wolfert, and Gustav Eje Henter. *A large, crowdsourced evaluation of gesture generation systems on common data: The GENEA Challenge 2020*. International Conference on Intelligent User Interfaces. 2021 \[[Paper\]](https://dl.acm.org/doi/pdf/10.1145/3397481.3450692) \[[Video\]](https://youtu.be/ja7IXGFrYGA) \[[Project Page\]](../_posts/2021-07-26-GENEA_challenge.md)

### 2020

* **Taras Kucherenko**, Patrik Jonell, Sanne van Waveren, Gustav Eje Henter, Simon Alexanderson, Iolanda Leite, and Hedvig Kjellström. *Gesticulator: A framework for semantically-aware speech-driven gesture generation*. International Conference on Multimodal Interaction (ICMI '20). 2020. \[[Paper\]](../papers/Gesticulator_ICMI_2020.pdf) \[[Code\]](https://github.com/svito-zar/Gesticulator) \[[Video\]](https://youtu.be/VQ8he6jjW08) \[[Project Page\]](../_posts/2020-08-03-Gesticulator.md) <span style="font-size: 11px;" class="badge badge-info mb-2">Best Paper Award<i class="fas fa-award"></i></span>

* **Taras Kucherenko** \*, Patrik Jonell\*, Youngwoo Yoon\*, Pieter Wolfert, and Gustav Eje Henter. *The GENEA Challenge 2020: Benchmarking gesture-generation systems on common data.* International Workshop on Generation and Evaluation of Non-Verbal Behaviour for Embodied Agents. 2020 \[[Paper\]](https://zenodo.org/record/4094697) \[[Video\]](https://youtu.be/Y-5dgBQk34c) \[[Project Page\]](../_posts/2021-07-26-GENEA_challenge.md)

* Patrik Jonell\*, **Taras Kucherenko**\*, Ilaria Torre, Jonas Beskow. *Can we trust online crowdworkers? Comparing online and offline participants in a preference test of virtual agents.* International Conference on Intelligent Virtual Agents (IVA'20). 2020 \[[Paper\]](https://dl.acm.org/doi/10.1145/3383652.3423860?cid=99659309831) \[[Video\]](https://youtu.be/OSuOvolaI6Y)


### 2019

* **Taras  Kucherenko**,  Dai  Hasegawa, Gustav  Eje  Henter, Naoshi  Kaneko, and Hedvig Kjellström.
*Analyzing input and output representations for speech-driven gesture generation.*
International Conference on Intelligent Virtual Agents (IVA '19), Paris, July 02–05, 2019
\[[Paper\]](https://dl.acm.org/doi/10.1145/3308532.3329472?cid=99659309831) \[[Code\]](https://github.com/GestureGeneration/Speech_driven_gesture_generation_with_autoencoder) \[[Video\]](https://youtu.be/Iv7UBe92zrw) \[[bib\]](https://people.kth.se/~ghe/pubs/bib/kucherenko2019analyzing.bib) \[[Project Page\]](../_posts/2020-01-14-Audio2Gestures.md)

* **Taras  Kucherenko**,  Dai  Hasegawa,  Naoshi  Kaneko,  Gustav  Eje  Henter, and Hedvig Kjellström. 
*On the importance of representations for speech-driven gesture generation.*
18th International Conference on Autonomous Agents and Multiagent Systems (AAMAS '19), Extended Abstract,
Montreal, May 13–17, 2019 \[[Paper\]](http://www.ifaamas.org/Proceedings/aamas2019/pdfs/p2072.pdf) \[[Poster\]](https://www.researchgate.net/publication/333148799_On_the_Importance_of_Representations_for_Speech-Driven_Gesture_Generation) \[[bib\]](https://people.kth.se/~ghe/pubs/bib/kucherenko2019importance.bib) \[[Project Page\]](../_posts/2020-01-14-Audio2Gestures.md)



### 2018

* **Taras  Kucherenko**. 
*Data driven non-verbal behavior generation for humanoid robots.*
International Conference on Multimodal Interaction (ICMI '18), Doctoral Consortium,
Boulder, Oct 12-17, 2018 \[[Paper\]](https://dl.acm.org/citation.cfm?doid=3242969.3264970)

* **Taras  Kucherenko**, Jonas Beskow and Hedvig Kjellström. 
*A neural network approach to missing marker reconstruction in human motion capture.*
arXiv preprint (2018) \[[Paper\]](https://www.researchgate.net/publication/323626902_A_Neural_Network_Approach_to_Missing_Marker_Reconstruction_in_Human_Motion_Capture) \[[Code\]](https://github.com/Svito-zar/NN-for-Missing-Marker-Reconstruction) \[[Video\]](https://youtu.be/mi75gzEhbHI) 

