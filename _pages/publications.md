---
layout: page
title: Publications
permalink: /publications/
---

My publications can also be found on [Google Scholar Citations](https://scholar.google.com/citations?user=aI_16pYAAAAJ&hl=en), [DBLP](https://dblp.uni-trier.de/pers/hd/k/Kucherenko:Taras), and [ResearchGate](https://www.researchgate.net/profile/Taras_Kucherenko). 

<link href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" rel="stylesheet" integrity="sha512-MoRNloxbStBcD8z3M/2BmnT+rg4IsMxPkXaGh2zD6LGNNFE80W3onsAhRcMAMrSoyWL9xD7Ert0men7vR8LUZg==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/css/mdb.min.css" integrity="sha512-RO38pBRxYH3SoOprtPTD86JFOclM51/XTIdEPh5j8sj4tp8jmQIx26twG52UaLi//hQldfrh7e51WzP9wuP32Q==" crossorigin="anonymous" />
<!-- Fonts & Icons -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css"  integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous">


### 2020

* **Taras Kucherenko**, Patrik Jonell, Youngwoo Yoon, Pieter Wolfert, and Gustav Eje Henter. *The GENEA Challenge 2020: Benchmarking gesture-generation systems on common data.* International Workshop on Generation and Evaluation of Non-Verbal Behaviour for Embodied Agents. 2020 [Paper](https://zenodo.org/record/4094697) [Video](https://youtu.be/Y-5dgBQk34c)

* **Taras  Kucherenko**,  Dai  Hasegawa, Naoshi Kaneko, Gustav  Eje  Henter, and Hedvig Kjellström.
*Moving fast and slow: Analysis of representations and post-processing in speech-driven automatic gesture generation.*
arxiv preprint. 2020
[Paper](https://www.researchgate.net/publication/343096046_Moving_fast_and_slow_Analysis_of_representations_and_post-processing_in_speech-driven_automatic_gesture_generation) [Code](https://github.com/GestureGeneration/Speech_driven_gesture_generation_with_autoencoder) [Video](https://youtu.be/Iv7UBe92zrw) [Project Page](../_posts/2020-01-14-Audio2Gestures.md)

* **Taras Kucherenko**, Patrik Jonell, Sanne van Waveren, Gustav Eje Henter, Simon Alexanderson, Iolanda Leite, and Hedvig Kjellström. *Gesticulator: A framework for semantically-aware speech-driven gesture generation*. International Conference on Multimodal Interaction (ICMI '20). 2020. [Paper](https://dl.acm.org/doi/10.1145/3382507.3418815) [Code](https://github.com/svito-zar/Gesticulator) [Video](https://youtu.be/VQ8he6jjW08) [Project Page](../_posts/2020-08-03-Gesticulator.md) <span style="font-size: 11px;" class="badge badge-info mb-2">Best Paper <i class="fas fa-award"></i></span>

* Patrik Jonell^, **Taras Kucherenko**^, Ilaria Torre, Jonas Beskow. *Can we trust online crowdworkers? Comparing online and offline participants in a preference test of virtual agents.* International Conference on Intelligent Virtual Agents (IVA'20). 2020 [Paper](https://dl.acm.org/doi/10.1145/3383652.3423860) [Video](https://youtu.be/OSuOvolaI6Y)

* Patrik Jonell, **Taras Kucherenko**, Gustav Eje Henter, Jonas Beskow. *Let’s face it: Probabilistic multi-modal interlocutor-aware generation of facial gestures in dyadic settings*. International Conference on Intelligent Virtual Agents (IVA'20). 2020. [Paper](https://raw.githubusercontent.com/jonepatr/lets_face_it/master/paper/jonell_lets_face_it.pdf) [Code](https://github.com/jonepatr/lets_face_it) [Video](https://youtu.be/RhazMS4L_bk) [Project Page](https://jonepatr.github.io/lets_face_it/) <span style="font-size: 11px;" class="badge badge-info mb-2">Best Paper <i class="fas fa-award"></i></span>

* Simon Alexanderson, Éva Székely, Gustav Eje Henter, **Taras Kucherenko**, and Jonas Beskow.
*Generating coherent spontaneous speech and gesture from text.* International Conference on Intelligent Virtual Agents (IVA'20). 2020. [Paper](https://dl.acm.org/doi/10.1145/3383652.3423874) [Project Page](https://simonalexanderson.github.io/IVA2020)

* Simon Alexanderson, Gustav  Eje  Henter, **Taras Kucherenko**,  and Jonas Beskow. *Style-Controllable Speech-Driven Gesture Synthesis Using Normalising Flows*. Computer Graphics Forum. 2020. (EuroGraphics 2020 <span style="font-size: 11px;" class="badge badge-info mb-2">Honourable mention <i class="fas fa-award"></i></span>) [Paper](../papers/alexanderson2020style.pdf) [Code](https://github.com/simonalexanderson/StyleGestures) [Video](https://youtu.be/egf3tjbWBQE)

### 2019
* Pieter Wolfert, **Taras Kucherenko**, Hedvig Kjellström, Tony Belpaeme. *Should Beat Gestures Be Learned Or Designed? A Benchmarking User Study.* ICDL-EPIROB 2019 Workshop on Naturalistic Non-Verbal and Affective Human-Robot Interactions, Oslo, August 19, 2019 [Paper](https://pieterwolfert.com/files/epirob_camera_final.pdf) [Code](https://github.com/Svito-zar/Speech_driven_gesture_generation) [Poster](../posters/should_gesture_be_learned_poster.pdf)

* Patrik Jonell, **Taras Kucherenko**, Erik Ekstedt, Jonas Beskow. *Learning Non-verbal Behavior for a Social Robot from YouTube Videos.* ICDL-EPIROB 2019 Workshop on Naturalistic Non-Verbal and Affective Human-Robot Interactions, Oslo, August 19, 2019 [Paper](../papers/learning_non-verbal_behavio(ICDL-EPIROB2019).pdf) [Code](https://github.com/jonepatr/glow-non-verbal-robot-behavior) [Poster](../posters/Jonel_2019_final_ICDL_poster.pdf)

* **Taras  Kucherenko**,  Dai  Hasegawa, Gustav  Eje  Henter, Naoshi  Kaneko, and Hedvig Kjellström.
*Analyzing input and output representations for speech-driven gesture generation.*
International Conference on Intelligent Virtual Agents (IVA '19), Paris, July 02–05, 2019
[Paper](https://dl.acm.org/doi/10.1145/3308532.3329472) [Code](https://github.com/GestureGeneration/Speech_driven_gesture_generation_with_autoencoder) [Video](https://youtu.be/Iv7UBe92zrw) [bib](https://people.kth.se/~ghe/pubs/bib/kucherenko2019analyzing.bib) [Project Page](../_posts/2020-01-14-Audio2Gestures.md)

* **Taras  Kucherenko**,  Dai  Hasegawa,  Naoshi  Kaneko,  Gustav  Eje  Henter, and Hedvig Kjellström. 
*On the importance of representations for speech-driven gesture generation.*
18th International Conference on Autonomous Agents and Multiagent Systems (AAMAS '19), Extended Abstract,
Montreal, May 13–17, 2019 [Paper](http://www.ifaamas.org/Proceedings/aamas2019/pdfs/p2072.pdf) [Poster](https://www.researchgate.net/publication/333148799_On_the_Importance_of_Representations_for_Speech-Driven_Gesture_Generation) [bib](https://people.kth.se/~ghe/pubs/bib/kucherenko2019importance.bib) [Project Page](../_posts/2020-01-14-Audio2Gestures.md)



### 2018

* **Taras  Kucherenko**. 
*Data driven non-verbal behavior generation for humanoid robots.*
International Conference on Multimodal Interaction (ICMI '18), Doctoral Consortium,
Boulder, Oct 12-17, 2018 [Paper](https://dl.acm.org/citation.cfm?doid=3242969.3264970)

* **Taras  Kucherenko**, Jonas Beskow and Hedvig Kjellström. 
*A neural network approach to missing marker reconstruction in human motion capture.*
arXiv preprint (2018) [Paper](https://www.researchgate.net/publication/323626902_A_Neural_Network_Approach_to_Missing_Marker_Reconstruction_in_Human_Motion_Capture) [Code](https://github.com/Svito-zar/NN-for-Missing-Marker-Reconstruction) [Video](https://youtu.be/mi75gzEhbHI) 


### 2017

* Patrik Jonell, Joseph Mendelson, Thomas Storskog, Goran Hagman, Per Ostberg, Iolanda Leite, **Taras Kucherenko**, Olga Mikheeva, Ulrika Akenine, Vesna Jelic, Alina Solomon, Jonas Beskow, Joakim Gustafson, Miia Kivipelto, Hedvig Kjellstrom. *Machine Learning and Social Robotics for Detecting Early Signs of Dementia*
arXiv preprint (2017) [Paper](https://arxiv.org/abs/1709.01613)

* **Taras  Kucherenko** and Hedvig Kjellström. *Towards Context-Preserving Human to Robot Motion Mapping.* The First Swedish Symposium on Deep Learning, Stockholm, 2017 [Paper](https://www.csc.kth.se/~hedvig/publications/ssdl_17.pdf)
